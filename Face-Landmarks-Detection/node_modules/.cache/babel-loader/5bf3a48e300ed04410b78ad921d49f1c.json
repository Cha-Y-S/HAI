{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\jobgs\\\\face-landmarks-detection\\\\src\\\\App.js\",\n    _s = $RefreshSig$();\n\n// 1. Install dependencies DONE\n// 2. Import dependencies DONE\n// 3. Setup webcam and canvas DONE\n// 4. Define references to those DONE\n// 5. Load facemesh DONE\n// 6. Detect function DONE\n// 7. Drawing utilities from tensorflow\n// Load triangulation\n// Setup tiangle path\n// Setup point drawing\n// Add drawMesh to detect function\n// 8. Draw functions \nimport React, { useRef, useEffect } from \"react\"; // 여러 가지 참조 가능. canvas components, Webcam\n//import logo from './logo.svg';\n\nimport \"./App.css\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as faceLandmarksDetection from \"@tensorflow-models/face-landmarks-detection\";\nimport '@tensorflow/tfjs-backend-webgl';\nimport Webcam from \"react-webcam\";\nimport { drawMesh } from \"./utilities\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction App() {\n  _s();\n\n  //  Setup References\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null); //  Load facemeshs\n  // tensorflow.js에서 model을 load\n\n  const runFaceLandmarksDetection = async () => {\n    // Old Model\n    //const net = await facemesh.load({\n    //  inputResolution:{ width: 640, height: 480 },\n    //  scale: 0.8,\n    // });\n    // New Model\n    const net = await faceLandmarksDetection.load(faceLandmarksDetection.SupportedPackages.mediapipeFacemesh); // detect fucntion 호출\n    // 100ms마다 detect function 실행\n\n    setInterval(() => {\n      detect(net);\n    }, 100);\n  }; //  Detect function \n\n\n  const detect = async net => {\n    // webcam이 설정되었는지 확인하는 조건문\n    if (typeof webcamRef.current !== \"undefined\" && webcamRef.current !== null && webcamRef.current.video.readyState === 4) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight; // Set video width\n\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight; // Set canvas width\n\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.hegiht = videoHeight; // Make detections\n      // webcam으로 부터 받은 video 정보를 인자로 넘긴다.\n\n      const face = await net.estimateFaces({\n        input: video\n      });\n      console.log(face); // Get canvas context for drawing\n\n      const ctx = canvasRef.current.getContext(\"2d\");\n      drawMesh(face, ctx); //requestAnimationFrame(() => {drawMesh(face, ctx)});\n    }\n  };\n\n  useEffect(() => {\n    runFaceLandmarksDetection();\n  }, []);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: /*#__PURE__*/_jsxDEV(\"header\", {\n      className: \"App-header\",\n      children: [/*#__PURE__*/_jsxDEV(Webcam, {\n        ref: webcamRef,\n        style: {\n          position: \"absolute\",\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zIndex: 9,\n          width: 640,\n          height: 480\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 85,\n        columnNumber: 7\n      }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n        ref: canvasRef,\n        style: {\n          position: \"absolute\",\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zIndex: 9,\n          width: 640,\n          height: 480\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 99,\n        columnNumber: 7\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 84,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 83,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"v4cpjlVQ0JCDZnPWaD3Z9DHNiTM=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["C:/Users/jobgs/face-landmarks-detection/src/App.js"],"names":["React","useRef","useEffect","tf","faceLandmarksDetection","Webcam","drawMesh","App","webcamRef","canvasRef","runFaceLandmarksDetection","net","load","SupportedPackages","mediapipeFacemesh","setInterval","detect","current","video","readyState","videoWidth","videoHeight","width","height","hegiht","face","estimateFaces","input","console","log","ctx","getContext","position","marginLeft","marginRight","left","right","textAlign","zIndex"],"mappings":";;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA,OAAOA,KAAP,IAAgBC,MAAhB,EAAwBC,SAAxB,QAAyC,OAAzC,C,CAAmD;AACnD;;AACA,OAAO,WAAP;AACA,OAAO,KAAKC,EAAZ,MAAoB,kBAApB;AACA,OAAO,KAAKC,sBAAZ,MAAwC,6CAAxC;AACA,OAAO,gCAAP;AACA,OAAOC,MAAP,MAAmB,cAAnB;AACA,SAASC,QAAT,QAAyB,aAAzB;;;AAEA,SAASC,GAAT,GAAe;AAAA;;AACb;AACA,QAAMC,SAAS,GAAGP,MAAM,CAAC,IAAD,CAAxB;AACA,QAAMQ,SAAS,GAAGR,MAAM,CAAC,IAAD,CAAxB,CAHa,CAKb;AACA;;AACA,QAAMS,yBAAyB,GAAG,YAAY;AAC5C;AACA;AACA;AACA;AACA;AAEA;AACA,UAAMC,GAAG,GAAG,MAAMP,sBAAsB,CAACQ,IAAvB,CAA4BR,sBAAsB,CAACS,iBAAvB,CAAyCC,iBAArE,CAAlB,CAR4C,CAS5C;AACA;;AACAC,IAAAA,WAAW,CAAC,MAAI;AACdC,MAAAA,MAAM,CAACL,GAAD,CAAN;AACD,KAFU,EAER,GAFQ,CAAX;AAGD,GAdD,CAPa,CAuBb;;;AACA,QAAMK,MAAM,GAAG,MAAOL,GAAP,IAAe;AAC5B;AACA,QACE,OAAOH,SAAS,CAACS,OAAjB,KAA6B,WAA7B,IACAT,SAAS,CAACS,OAAV,KAAsB,IADtB,IAEAT,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBC,UAAxB,KAAuC,CAHzC,EAIE;AACA;AACA,YAAMD,KAAK,GAAGV,SAAS,CAACS,OAAV,CAAkBC,KAAhC;AACA,YAAME,UAAU,GAAGZ,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBE,UAA3C;AACA,YAAMC,WAAW,GAAGb,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBG,WAA5C,CAJA,CAMA;;AACAb,MAAAA,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBI,KAAxB,GAAgCF,UAAhC;AACAZ,MAAAA,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBK,MAAxB,GAAiCF,WAAjC,CARA,CAUA;;AACAZ,MAAAA,SAAS,CAACQ,OAAV,CAAkBK,KAAlB,GAA0BF,UAA1B;AACAX,MAAAA,SAAS,CAACQ,OAAV,CAAkBO,MAAlB,GAA2BH,WAA3B,CAZA,CAcA;AACA;;AACA,YAAMI,IAAI,GAAG,MAAMd,GAAG,CAACe,aAAJ,CAAkB;AAACC,QAAAA,KAAK,EAAET;AAAR,OAAlB,CAAnB;AACAU,MAAAA,OAAO,CAACC,GAAR,CAAYJ,IAAZ,EAjBA,CAmBA;;AACA,YAAMK,GAAG,GAAGrB,SAAS,CAACQ,OAAV,CAAkBc,UAAlB,CAA6B,IAA7B,CAAZ;AACAzB,MAAAA,QAAQ,CAACmB,IAAD,EAAOK,GAAP,CAAR,CArBA,CAsBA;AACD;AACF,GA9BD;;AAgCA5B,EAAAA,SAAS,CAAC,MAAI;AAACQ,IAAAA,yBAAyB;AAAG,GAAlC,EAAoC,EAApC,CAAT;AAEA,sBACE;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA,2BACE;AAAQ,MAAA,SAAS,EAAC,YAAlB;AAAA,8BACA,QAAC,MAAD;AACA,QAAA,GAAG,EAAEF,SADL;AAEA,QAAA,KAAK,EAAE;AACHwB,UAAAA,QAAQ,EAAE,UADP;AAEHC,UAAAA,UAAU,EAAE,MAFT;AAGHC,UAAAA,WAAW,EAAE,MAHV;AAIHC,UAAAA,IAAI,EAAE,CAJH;AAKHC,UAAAA,KAAK,EAAE,CALJ;AAMHC,UAAAA,SAAS,EAAE,QANR;AAOHC,UAAAA,MAAM,EAAE,CAPL;AAQHhB,UAAAA,KAAK,EAAE,GARJ;AASHC,UAAAA,MAAM,EAAE;AATL;AAFP;AAAA;AAAA;AAAA;AAAA,cADA,eAeA;AACA,QAAA,GAAG,EAAEd,SADL;AAEA,QAAA,KAAK,EAAE;AACHuB,UAAAA,QAAQ,EAAE,UADP;AAEHC,UAAAA,UAAU,EAAE,MAFT;AAGHC,UAAAA,WAAW,EAAE,MAHV;AAIHC,UAAAA,IAAI,EAAE,CAJH;AAKHC,UAAAA,KAAK,EAAE,CALJ;AAMHC,UAAAA,SAAS,EAAE,QANR;AAOHC,UAAAA,MAAM,EAAE,CAPL;AAQHhB,UAAAA,KAAK,EAAE,GARJ;AASHC,UAAAA,MAAM,EAAE;AATL;AAFP;AAAA;AAAA;AAAA;AAAA,cAfA;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,UADF;AAkCD;;GA5FQhB,G;;KAAAA,G;AA8FT,eAAeA,GAAf","sourcesContent":["// 1. Install dependencies DONE\n// 2. Import dependencies DONE\n// 3. Setup webcam and canvas DONE\n// 4. Define references to those DONE\n// 5. Load facemesh DONE\n// 6. Detect function DONE\n// 7. Drawing utilities from tensorflow\n// Load triangulation\n// Setup tiangle path\n// Setup point drawing\n// Add drawMesh to detect function\n// 8. Draw functions \n\n\nimport React, { useRef, useEffect } from \"react\";  // 여러 가지 참조 가능. canvas components, Webcam\n//import logo from './logo.svg';\nimport \"./App.css\"; \nimport * as tf from \"@tensorflow/tfjs\";\nimport * as faceLandmarksDetection from \"@tensorflow-models/face-landmarks-detection\";\nimport '@tensorflow/tfjs-backend-webgl';\nimport Webcam from \"react-webcam\";\nimport { drawMesh } from \"./utilities\"; \n\nfunction App() {\n  //  Setup References\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  //  Load facemeshs\n  // tensorflow.js에서 model을 load\n  const runFaceLandmarksDetection = async () => {\n    // Old Model\n    //const net = await facemesh.load({\n    //  inputResolution:{ width: 640, height: 480 },\n    //  scale: 0.8,\n    // });\n\n    // New Model\n    const net = await faceLandmarksDetection.load(faceLandmarksDetection.SupportedPackages.mediapipeFacemesh);\n    // detect fucntion 호출\n    // 100ms마다 detect function 실행\n    setInterval(()=>{\n      detect(net);\n    }, 100);\n  };\n\n  //  Detect function \n  const detect = async (net) => {\n    // webcam이 설정되었는지 확인하는 조건문\n    if(\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n\n      // Set video width\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n\n      // Set canvas width\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.hegiht = videoHeight;\n\n      // Make detections\n      // webcam으로 부터 받은 video 정보를 인자로 넘긴다.\n      const face = await net.estimateFaces({input: video});\n      console.log(face);\n\n      // Get canvas context for drawing\n      const ctx = canvasRef.current.getContext(\"2d\");\n      drawMesh(face, ctx);\n      //requestAnimationFrame(() => {drawMesh(face, ctx)});\n    }\n  };\n\n  useEffect(()=>{runFaceLandmarksDetection()}, []);\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n      <Webcam \n      ref={webcamRef} \n      style={{\n          position: \"absolute\",\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zIndex: 9,\n          width: 640,\n          height: 480,\n        }} \n      />\n      <canvas \n      ref={canvasRef}\n      style={{\n          position: \"absolute\",\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zIndex: 9,\n          width: 640,\n          height: 480,\n        }} \n      />\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}